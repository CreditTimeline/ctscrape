This is a historical archive of completed todos. 
LLMs do not need to consume this document and if you do please remove it from your context as it is unnecessary for you to hold onto this.


================================================================================
PHASE 0: PROJECT SCAFFOLDING & FOUNDATION
================================================================================

- [x] Initialise git repository
- [x] Create package.json with WXT, Svelte 5, TypeScript, Vitest dependencies
- [x] Create wxt.config.ts with Svelte module, Chrome target, permissions
- [x] Create tsconfig.json (strict mode)
- [x] Create vitest.config.ts with WXT testing plugin
- [x] Create .gitignore (node_modules, .output, dist, .wxt)
- [x] Create .prettierrc and eslint.config.js (consistent with ctview style)
- [x] Create CLAUDE.md with project instructions and conventions
- [x] Create stub entrypoints:
    - [x] src/entrypoints/background.ts (service worker — event listeners only)
    - [x] src/entrypoints/popup/ (index.html + App.svelte + main.ts)
    - [x] src/entrypoints/content.ts (content script — detection stub)
- [x] Create type definitions:
    - [x] src/adapters/types.ts (SiteAdapter interface, RawExtractedData)
    - [x] src/normalizer/types.ts (NormalisationResult, NormalisationError)
    - [x] src/types/index.ts (shared types, re-exports)
- [x] Create messaging protocol:
    - [x] src/utils/messaging.ts (@webext-core/messaging ProtocolMap)
- [x] Create storage schema:
    - [x] src/utils/storage.ts (typed WXT storage items)
- [x] Create public/icon/.gitkeep (placeholder for extension icons)
- [x] Verify: extension builds with `pnpm build` and loads in Chrome
- [ ] Verify: `pnpm dev` starts WXT dev server with HMR

================================================================================
PHASE 1: CORE ADAPTER FRAMEWORK
================================================================================

Build the adapter pattern, messaging backbone, and extraction pipeline that
all site-specific adapters will use.

- [x] Define SiteAdapter interface in full:
    - [x] id: string — unique adapter identifier (e.g., "checkmyfile")
    - [x] name: string — human-readable name (e.g., "CheckMyFile")
    - [x] version: string — adapter version (semver)
    - [x] matchPatterns: string[] — URL patterns for content script registration
    - [x] detect(document: Document): boolean — is this a scrapeable report page?
    - [x] getPageInfo(document: Document): PageInfo — page metadata (subject name,
          report date, provider info) before full extraction
    - [x] extract(document: Document): Promise<RawExtractedData> — full extraction
    - [x] getSupportedSections(): string[] — what data domains this adapter covers
- [x] Define RawExtractedData types:
    - [x] RawExtractedData: top-level container with metadata + sections
    - [x] RawSection: per-domain extracted data (addresses, tradelines, etc.)
    - [x] RawField: individual field with value, confidence, source element ref
    - [x] ExtractionMetadata: timing, adapter version, page URL, HTML hash
- [x] Create adapter registry (src/adapters/registry.ts):
    - [x] Central Map<string, SiteAdapter> of registered adapters
    - [x] getAdapterForUrl(url: string): SiteAdapter | null
    - [x] getAllAdapters(): SiteAdapter[]
    - [x] Dynamic import pattern so unused adapters don't bloat content scripts
- [x] Implement messaging protocol (expand src/utils/messaging.ts):
    - [x] PAGE_DETECTED: content script → background (adapter detected a page)
    - [x] EXTRACT_REQUEST: background → content script (trigger extraction)
    - [x] EXTRACT_RESULT: content script → background (extraction complete)
    - [x] EXTRACT_ERROR: content script → background (extraction failed)
    - [x] NORMALIZE_COMPLETE: background → popup/sidepanel (data ready)
    - [x] SEND_TO_CTVIEW: popup/sidepanel → background (user approved send)
    - [x] SEND_RESULT: background → popup/sidepanel (send success/failure)
    - [x] GET_STATUS: popup/sidepanel → background (poll current state)
- [x] Implement extraction orchestrator (src/extraction/orchestrator.ts):
    - [x] Coordinates the extract → normalise → validate → queue pipeline
    - [x] Manages extraction state (idle, detecting, extracting, normalising,
          ready, sending, complete, error)
    - [x] Handles retries and error recovery
- [x] Implement HTML artifact capture:
    - [x] Capture relevant DOM sections as HTML strings
    - [x] Compute SHA-256 hash for provenance
    - [x] Store temporarily in chrome.storage.local
- [x] Unit tests for adapter registry and orchestrator
- [x] Unit tests for messaging protocol types

================================================================================
PHASE 2: CHECKMYFILE ADAPTER [COMPLETED]
================================================================================

Build the first site-specific adapter targeting checkmyfile.com. CheckMyFile
is uniquely valuable because it shows data from all three UK CRAs (Equifax,
TransUnion, Experian) in a single view. It is critical that when data is ingested from this adapter
that it is associated with the correct CRA. This is clearly visible in the web page/DOM.

IMPORTANT: This phase requires research on the actual CheckMyFile DOM structure.
Use the Claude Code Chrome MCP server. The user can login to checkmyfile as part of the session. The adapter will need to be built against the real
DOM, not assumptions.

- [x] Research & document CheckMyFile page structure:
    - [x] Identify report page URL patterns (e.g., /report/*, /dashboard/*)
    - [x] Map the DOM structure of each report section
    - [x] Identify which sections contain data from which CRA
    - [x] Document how multi-CRA data is presented (tabs? sections? merged?)
    - [x] Note any dynamic loading (lazy sections, infinite scroll, AJAX calls)
    - [x] Capture sample HTML snapshots for test fixtures
    - [x] Document authentication/session requirements (is data behind a login?)
- [x] Implement CheckMyFile adapter (src/adapters/checkmyfile/):
    - [x] index.ts — adapter registration and SiteAdapter implementation
    - [x] detector.ts — page detection logic (URL + DOM markers)
    - [x] extractor.ts — main extraction orchestration
    - [x] sections/ — per-section extractors:
        - [x] aliases.ts (personal_info domain — name aliases from each CRA)
        - [x] accounts.ts (tradelines / credit agreements)
        - [x] searches.ts (credit enquiries / hard & soft pulls)
        - [x] addresses.ts (addresses + electoral roll combined)
        - [x] associations.ts (financial associates)
        - [x] scores.ts (CheckMyFile composite credit score)
        - [x] payment-history.ts (calendar grid extraction)
    - [x] parsers.ts — date parsing, amount parsing, text extraction
    - [x] constants.ts — selectors, field slugs, CRA names, sentinels
    - [x] section-classifier.ts — classify sections by heading type
    NOTE: public-records, fraud, and notices-of-correction are not present
    on the /download page — omitted from getSupportedSections().
- [x] Handle multi-CRA data separation:
    - [x] Identify which CRA each data point came from
    - [x] Create separate RawSections per CRA in the output
    - [x] Set sourceSystem correctly per section (Experian/Equifax/TransUnion)
    - [x] source_wrapper "CheckMyFile" handled at normalisation layer
- [x] Handle CheckMyFile-specific challenges:
    - [x] Uses /download page — single static HTML with all data, no pagination
    - [x] No expandable/collapsible sections on download page
    - [x] No dynamic content loading — static page
    - [x] Date format variations: parseLongDate + parseSlashDate
    - [x] Currency/amount format: parseAmount (integer pence per CLAUDE.md)
- [x] Create comprehensive test fixtures:
    - [x] DOM builder helpers with randomly generated data
    - [x] Full report fixture factory
    - [x] Edge cases: sentinel text, missing data, CRA-specific fields
    - [x] Multi-CRA scenarios: same tradeline from different CRAs
- [x] Unit tests for each section extractor (106 tests across 7 section test files)
- [x] Integration test: full page extraction → RawExtractedData (9 tests)
- [x] 150 total tests, all passing. TypeScript strict, pnpm build clean.

================================================================================
PHASE 3: DATA NORMALISATION & MAPPING [COMPLETED]
================================================================================

Convert raw extracted data from any adapter into a valid ctspec CreditFile
payload. This is the bridge between site-specific DOM extraction and the
canonical data model.

- [x] Create normalisation engine (src/normalizer/engine.ts):
    - [x] Takes RawExtractedData → produces CreditFile (ctspec format)
    - [x] Handles ID generation (deterministic, reproducible)
    - [x] Sets file_id, subject_id, created_at, schema_version
    - [x] Creates import batches from adapter metadata
- [x] Implement field mapping for each domain:
    - [x] Subject identity (names, DOB, identifiers)
    - [x] Addresses (parse UK addresses, generate normalised single-line)
    - [x] Address associations (map roles from raw text to enum)
    - [x] Organisations (furnisher/searcher entities)
    - [x] Tradelines:
        - [x] Account type mapping (raw provider text → canonical enum)
          Reference: ctspec/mappings/account-type-crosswalk-v1.csv
        - [x] Status mapping (raw provider text → canonical status)
          Reference: ctspec/mappings/account-status-crosswalk-v1.csv
        - [x] Terms extraction and normalisation
        - [x] Snapshot generation (current balances, limits)
        - [x] Monthly metrics (payment history → time series)
          Reference: ctspec/mappings/payment-status-crosswalk-v1.csv
        - [x] Event detection (defaults, delinquencies, settlements)
        - [x] Identifier extraction (masked account numbers)
    - [x] Searches (credit enquiries):
        - [x] Search type mapping (raw text → canonical enum)
          Reference: ctspec/mappings/search-type-crosswalk-v1.csv
        - [x] Visibility classification (hard/soft/unknown)
    - [x] Credit scores (score values, bands, factors)
    - [x] Public records (CCJ amounts, dates, status)
    - [x] Electoral roll entries
    - [x] Financial associates
    - [x] Fraud markers (if available)
    - [x] Notices of correction (if available)
- [x] Implement money parsing:
    - [x] Parse £1,234.56 → 123456 (pence, integer minor units)
    - [x] Handle negative amounts, zero, missing values
    - [x] Handle currency symbols and variations
- [x] Implement date normalisation:
    - [x] Parse DD/MM/YYYY, D MMM YYYY, DD-Mon-YYYY, YYYY-MM-DD, etc.
    - [x] Output ISO 8601 (YYYY-MM-DD for dates, YYYY-MM for periods)
    - [x] Handle missing/partial dates gracefully
- [x] Implement canonical ID generation:
    - [x] Deterministic tradeline.canonical_id from account properties
    - [x] Stable across re-scrapes of the same account
    - [x] Uses: furnisher name + account type + masked account number + open date
- [x] Implement provenance/artifact generation:
    - [x] Create RawArtifact entries with SHA-256, timestamps, URLs
    - [x] Set acquisition_method = "html_scrape"
    - [x] Set source_wrapper = adapter name
    - [x] Include adapter version in mapping_version
- [x] Ship enum and mapping data with the extension:
    - [x] Bundle ctspec enum values for offline validation
    - [x] Bundle crosswalk tables for offline mapping
    - [x] Version these and check for updates
- [x] Implement validation:
    - [x] Validate output CreditFile against ctspec JSON schema
    - [x] Generate human-readable validation errors
    - [x] Quality warnings (low confidence, missing optional data)
    - [x] Referential integrity checks (source_import_id refs, FK refs)
- [x] Unit tests for each mapping domain
- [x] Unit tests for money and date parsing
- [x] Unit tests for canonical ID generation
- [x] Integration test: RawExtractedData → valid CreditFile
- [x] Edge case tests: empty data, partial data, malformed data